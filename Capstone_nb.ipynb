{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Input\n",
    "\n",
    "The datasets used in this project are available from ['The Cancer Genome Atlas' (TCGA)](www.http://cancergenome.nih.gov/) consortium.  Clinical and RNA-seq gene count data sets can be downloaded via a provided data portal, or using an R package called [TCGA2STAT](https://cran.r-project.org/web/packages/TCGA2STAT/index.html).  The R script used to download the data sets for this project and write files locally in [feather](https://github.com/wesm/feather)  format are available in the project repository [here](https://github.com/CCThompson82/MLE_capstone/tree/master/Dataset_setup).  Datasets are also stored in this project's repository [here](https://github.com/CCThompson82/MLE_capstone/tree/master/feather_files).  The R script is not necessary for dataset download, but can be run locally to obtain the most up to date clinical information from TCGA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical data set imported!\n",
      "Features: 21 \n",
      "Patients: 499\n",
      "\n",
      " The following features do not provide any information: \n",
      " ['Composite.Element.REF' 'ethnicity' 'gender' 'pathologicstage'\n",
      " 'pathologyMstage' 'tumortissuesite'] \n",
      "\n",
      "Variables that are not known at initial diagnosis: \n",
      " ['daystodeath' 'daystolastfollowup' 'daystopsa' 'histologicaltype'\n",
      " 'numberoflymphnodes' 'pathologyTstage' 'radiationtherapy' 'residualtumor'\n",
      " 'vitalstatus'] \n",
      "\n",
      "Variables that are known at the time of diagnosis:\n",
      " ['clinical_index' 'dateofinitialpathologicdiagnosis' 'gleasonscore'\n",
      " 'pathologyNstage' 'psavalue' 'race' 'yearstobirth']\n",
      "\n",
      "\n",
      "Gene Counts data set imported!\n",
      "Features: 20501 \n",
      "Patients: 497\n",
      "\n",
      "\n",
      "Transforming gene counts to transcript per million (TPM)\n",
      "\n",
      "Transformation Successful!\n",
      "\n",
      "497 Gene count estimate profiles have been transformed from gene counts to transcripts per million reads (TPM)\n"
     ]
    }
   ],
   "source": [
    "%run -i Dataset_cleanup/arrange_DF.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "## Clinical Information and metastasis label\n",
    "There is missing clinical data in many of the features, including what will become the outcome label ('pathologyNstage' - metastasis state).  The series **'y_all'** is the full list of pathologyNstage, where 'n1' represents metastasis, and 'n0' represents no metastasis observed to date.  Some observations have no metastasis state recorded and are represented by NaN in y_all.  These are removed for the trimmed **'y'** series.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = (('n0', y_all[y_all =='n0'].shape[0]), \n",
    "     ('n1', y_all[y_all =='n1'].shape[0]), \n",
    "     ('missing' , y_all[y_all.isnull()].shape[0]))\n",
    "exp_fig = plt.figure(figsize=(5 , 5))\n",
    "A = exp_fig.add_subplot(1,1,1)\n",
    "ind = A.bar(range(0,3), height= [D[0][1], D[1][1], D[2][1]], align='center', color = 'grey')\n",
    "A.set_xticks(range(0,3))\n",
    "A.set_ylabel('Frequency', fontsize=16)\n",
    "A.set_xlabel('Metastasis state', fontsize=16)\n",
    "A.set_ylim(0,400)\n",
    "A.set_xticklabels([D[0][0], D[1][0], D[2][0]])  #Must be a better way to do this as tuples (D, in this case) are not ordered?\n",
    "ep = plt.show\n",
    "exp_fig.savefig('Figures/LabelCount.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gleason Score versus Metastasis analysis\n",
    "The Gleason score is the gold-standard diagnostic test for cancer severity, but is not highly correlative with metastatic disease.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clinical['gleasonscore'] = pd.to_numeric(clinical['gleasonscore'], errors= 'coerce')\n",
    "clinical['gleasonscore'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GS_hist = plt.figure(figsize=(5,5))\n",
    "A = GS_hist.add_subplot(1,1,1)\n",
    "sub = (('n1', ))\n",
    "\n",
    "subs = [clinical.loc[y_all[y_all == 'n0'].index]['gleasonscore'],\n",
    "        clinical.loc[y_all[y_all == 'n1'].index]['gleasonscore'],\n",
    "        clinical.loc[y_all[y_all.isnull()].index]['gleasonscore']]\n",
    "\n",
    "bins = [5.99, 6.99, 7.99, 8.99, 9.99, 10.99]\n",
    "A.hist(subs, bins, label =['n0', 'n1', 'unknown'], color = ['blue','red','grey'], stacked = True)\n",
    "A.set_ylim(0,275)\n",
    "A.set_ylabel('Count', fontsize=16)\n",
    "A.set_xlabel('Gleason Score', fontsize =16)\n",
    "A.legend()\n",
    "plt.show\n",
    "GS_hist.savefig('Figures/GleasonHist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that no metastases are recorded in those specimens graded at a Gleason score of 6.  This represents an opportunity to replace the missing data label with the most likely pathology state, n0, to more efficiently use the small data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Define the indices where gleasonscore == 6 and pathologyNstage is null\"\"\"\n",
    "set(y_all[y_all.isnull()].index).intersection(list(clinical[clinical['gleasonscore'] == 6].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all.loc[set(y_all[y_all.isnull()].index).intersection(list(clinical[clinical['gleasonscore'] == 6].index))] = 'n0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GS_hist = plt.figure(figsize=(5,5))\n",
    "A = GS_hist.add_subplot(1,1,1)\n",
    "sub = (('n1', ))\n",
    "\n",
    "subs = [clinical.loc[y_all[y_all == 'n0'].index]['gleasonscore'],\n",
    "        clinical.loc[y_all[y_all == 'n1'].index]['gleasonscore'],\n",
    "        clinical.loc[y_all[y_all.isnull()].index]['gleasonscore']]\n",
    "\n",
    "bins = [5.99, 6.99, 7.99, 8.99, 9.99, 10.99]\n",
    "A.hist(subs, bins, label =['n0', 'n1', 'unknown'], color = ['blue','red','grey'], stacked = True)\n",
    "A.set_ylim(0,275)\n",
    "A.set_ylabel('Count', fontsize=16)\n",
    "A.set_xlabel('Gleason Score', fontsize =16)\n",
    "A.legend()\n",
    "plt.show\n",
    "GS_hist.savefig('Figures/GleasonHist2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Activation (Gene counts) Dataset\n",
    "The starting dataset, **'X_all'**, includes the transformed transcript per million (TPM) estimates for all RNA-seq profiles.  However some of the observations in this set do not have corresponding y_labels, as the clinical data set contains missing information.\n",
    "\n",
    "Therefore X_all was trimmed to include only those observations where a finite y label exists, to yield **'X'**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Total observations in original dataset:\",clinical.shape[0])\n",
    "\n",
    "not_labeled = y_all[y_all.isnull()] \n",
    "y = y_all[y_all.notnull()]\n",
    "\n",
    "print(\"\\nObservations with metastasis label:\",y.shape[0])\n",
    "print(\"Unlabeled observations (removed:)\",not_labeled.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Limit X to only observations where a target label is present.\"\"\"\n",
    "X = X_all.loc[set(y.index).intersection(X_all.index)]  #Only observations that also have a known metastasis state are kept.\n",
    "y = y.loc[set(X.index).intersection(y.index)]\n",
    "print(\"X dimensions:\",X.shape,\"\\ny dimensions:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_no_y = X_all.loc[list(not_labeled.index)]\n",
    "print(\"Dimensions of unlabeled dataset:\",X_no_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Check to determine if any clinical information is missing\"\"\"\n",
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gleason = clinical['gleasonscore']\n",
    "#print(gleason.shape)\n",
    "age = pd.to_numeric(clinical['yearstobirth'], errors = 'coerce')\n",
    "age.fillna(value = np.mean(age), inplace=True)\n",
    "psa = pd.to_numeric(clinical['psavalue'], errors= 'coerce')\n",
    "psa.fillna(value = np.mean(psa), inplace =True)\n",
    "#gleason = gleason.loc[y.index]\n",
    "\n",
    "clinicalDF_all = pd.DataFrame({'gleason': gleason,\n",
    "                            'age':age ,\n",
    "                            'psa' : psa,\n",
    "                            'y' : y_all}, index=X_all.index)\n",
    "clinicalDF = clinicalDF_all.loc[y.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clinicalDF.drop(['y'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clinicalDF = clinicalDF.reindex(y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm = pd.scatter_matrix(clinicalDF, \n",
    "                       alpha=0.25, \n",
    "                       figsize= (10,10), \n",
    "                       diagonal = 'kde', \n",
    "                       c = y.replace({'n1': 'red','n0':'blue'}), \n",
    "                       s = 125)\n",
    "\n",
    "plt.savefig(\"Figures/ClinScatterMatrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "K_selector = SelectKBest(f_classif, k = 'all') # using k=all here and will filter based on F-stat later.  \n",
    "K = K_selector.fit(X, y)\n",
    "K_df = pd.DataFrame({'Gene':X.columns, 'F_score':K.scores_})\n",
    "K_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_fig = plt.figure(figsize=(15,5))\n",
    "A = F_fig.add_subplot(1,2,1)\n",
    "A.hist(K_df['F_score'], bins=range(0,45,1), facecolor='green')\n",
    "#A.set_yscale('log')\n",
    "A.set_ylabel('Count', fontsize=16)\n",
    "A.set_xlabel(\"F-statistic\", fontsize=16)\n",
    "F_fig.suptitle(\"Distribution of F-statistics for metatastasis state group comparison of gene expression\", fontsize = 18)\n",
    "B = F_fig.add_subplot(1,2,2)\n",
    "B.hist(K_df['F_score'], bins=range(0,45,1), facecolor='green')\n",
    "B.set_yscale('log')\n",
    "B.set_ylabel('Count', fontsize=16)\n",
    "B.set_xlabel(\"F-statistic\", fontsize=16)\n",
    "#B.set_title(\"Distribution of F-statistics for metatastasis state group comparison of gene expression\", fontsize = 18)\n",
    "plt.show()\n",
    "F_fig.savefig(\"Figures/FDist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## Prepare for Analysis\n",
    "### Generate Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, fbeta_score, classification_report, log_loss\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Scorers needed throughout code:\"\"\"\n",
    "from sklearn.metrics import make_scorer\n",
    "LL_scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True, needs_threshold=False)\n",
    "MCC_scorer = make_scorer(matthews_corrcoef, greater_is_better=True, needs_proba=False, needs_threshold=False)\n",
    "fbeta_scorer = make_scorer(fbeta_score, greater_is_better=True, needs_proba=False, needs_threshold=False, pos_label='n1', beta = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Logistic Regression Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed and Folds for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "folds = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handles for Graph legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "blue = mpatches.Patch(color ='blue', label ='n0')\n",
    "red = mpatches.Patch(color='red', label = 'n1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_k = round(len(y)*0.70)\n",
    "test_k = len(y) - train_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Split samples into train and test sets, stratified by Gleason score\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size= test_k, \n",
    "                                                    train_size = train_k,\n",
    "                                                    random_state = seed,\n",
    "                                                    stratify = clinicalDF['gleason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clinicalDF_train = clinicalDF.loc[X_train.index,:]\n",
    "clinicalDF_test = clinicalDF.loc[X_test.index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical Information Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_LR_clin = LogisticRegression(penalty='l2',\n",
    "                              dual=False,\n",
    "                              tol=0.0001,\n",
    "                              C=1,\n",
    "                              fit_intercept=True,\n",
    "                              intercept_scaling=1,\n",
    "                              class_weight='balanced',\n",
    "                              random_state=123,\n",
    "                              solver='liblinear',\n",
    "                              max_iter=100,\n",
    "                              multi_class='ovr',\n",
    "                              verbose=0,\n",
    "                              warm_start=False,\n",
    "                              n_jobs=1)\n",
    "\n",
    "clf_LR_clin.fit(clinicalDF_train, y_train)  #use training set for model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_LR_clin = LogisticRegression(penalty='l2',\n",
    "                              dual=False,\n",
    "                              tol=0.0001,\n",
    "                              C=1,\n",
    "                              fit_intercept=True,\n",
    "                              intercept_scaling=1,\n",
    "                              class_weight='balanced',\n",
    "                              random_state=123,\n",
    "                              solver='liblinear',\n",
    "                              max_iter=100,\n",
    "                              multi_class='ovr',\n",
    "                              verbose=0,\n",
    "                              warm_start=False,\n",
    "                              n_jobs=1)\n",
    "\n",
    "clf_LR_clin.fit(clinicalDF_train, y_train)  #use training set for model learning\n",
    "\n",
    "bench_fig = plt.figure(figsize=(15,5))\n",
    "A= bench_fig.add_subplot(1,2,1)\n",
    "B = bench_fig.add_subplot(1,2,2)\n",
    "A.scatter(clinicalDF_train.loc[:,'gleason'], \n",
    "          clf_LR_clin.predict_proba(clinicalDF_train)[:,1], \n",
    "          color = y_train.replace({'n1':'red', 'n0': 'blue', 'NaN':'grey'}),\n",
    "          alpha = 0.3,\n",
    "          s = 25)\n",
    "A.set_ylabel('Benchmark model probability of metastasis')\n",
    "A.set_ylim(0,1)\n",
    "B.set_ylim(0,1)\n",
    "A.set_xlabel('Gleason')\n",
    "plt.suptitle('Prognosis of metastasis risk based on features available at presentation', fontsize=20)\n",
    "A.set_title('Training Set')\n",
    "B.set_title('Validation Set')\n",
    "B.scatter(clinicalDF_test.loc[:,'gleason'],\n",
    "          clf_LR_clin.predict_proba(clinicalDF_test)[:,1],\n",
    "          color = y_test.replace({'n1':'red', 'n0': 'blue', 'NaN':'grey'}),\n",
    "          alpha = 0.5,\n",
    "          s = 25)\n",
    "B.set_xlabel('Gleason')\n",
    "B.set_ylabel('Benchmark model probability of metastasis')\n",
    "bench_fig.legend(labels = ['n0', 'n1'], handles = [blue, red], loc = 5)\n",
    "bench_fig.suptitle(\"Benchmark Model\", fontsize=20)\n",
    "plt.show\n",
    "bench_fig.savefig('Figures/benchmark.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'features':clinicalDF.columns, 'coefficient': clf_LR_clin.coef_[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"Benchmark Performance on Train dataset\"\n",
    "print(clf_LR_clin)\n",
    "print('\\nNull F beta: ', fbeta_score(y_train, clf_LR_clin.predict(clinicalDF_train), pos_label='n1',beta=2))\n",
    "print('\\nMCC: ',matthews_corrcoef(y_train, clf_LR_clin.predict(clinicalDF_train)),\"\\n\")\n",
    "print(classification_report(y_train, clf_LR_clin.predict(clinicalDF_train), labels = ['n0','n1']))\n",
    "print('\\nLogLoss: ', log_loss(y_train.replace({'n0':0, 'n1':1}), \n",
    "         clf_LR_clin.predict_proba(clinicalDF_train)[:,1]))\n",
    "\n",
    "training_stat = pd.DataFrame({'F2': fbeta_score(y_train, clf_LR_clin.predict(clinicalDF_train), pos_label='n1',beta=2),\n",
    "                            'MCC': matthews_corrcoef(y_train, clf_LR_clin.predict(clinicalDF_train)),\n",
    "                            'LogLoss':log_loss(y_train.replace({'n0':0, 'n1':1}), \n",
    "                                      clf_LR_clin.predict_proba(clinicalDF_train)[:,1])}, index = ['clinical_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"Benchmark Performance on Test dataset\"\n",
    "print(clf_LR_clin)\n",
    "print('\\nNull F beta: ', fbeta_score(y_test, clf_LR_clin.predict(clinicalDF_test), pos_label='n1',beta=2))\n",
    "print('\\nMCC: ',matthews_corrcoef(y_test, clf_LR_clin.predict(clinicalDF_test)),\"\\n\")\n",
    "print(classification_report(y_test, clf_LR_clin.predict(clinicalDF_test), labels = ['n0','n1']))\n",
    "print('\\nLogLoss: ', log_loss(y_test.replace({'n0':0, 'n1':1}), \n",
    "         clf_LR_clin.predict_proba(clinicalDF_test)[:,1]))\n",
    "\n",
    "metric_stat = pd.DataFrame({'F2': fbeta_score(y_test, clf_LR_clin.predict(clinicalDF_test), pos_label='n1',beta=2),\n",
    "                            'MCC': matthews_corrcoef(y_test, clf_LR_clin.predict(clinicalDF_test)),\n",
    "                            'LogLoss':log_loss(y_test.replace({'n0':0, 'n1':1}), \n",
    "                                      clf_LR_clin.predict_proba(clinicalDF_test)[:,1])}, index = ['clinical_only'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction\n",
    "### Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Importance Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(n_estimators=1000, \n",
    "                                criterion='gini', \n",
    "                                max_depth=3, \n",
    "                                min_samples_split=30, \n",
    "                                min_samples_leaf=5, \n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                max_features= 'auto', \n",
    "                                max_leaf_nodes=None, \n",
    "                                bootstrap=True, \n",
    "                                oob_score=False, \n",
    "                                n_jobs=1, \n",
    "                                random_state=seed, \n",
    "                                verbose=0, \n",
    "                                warm_start=False, \n",
    "                                class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_RF.fit(X, y)\n",
    "Gini_DF = pd.DataFrame({'Gini' :clf_RF.feature_importances_}, index=X.columns).sort_values(by = ['Gini'], axis = 0, ascending = False)\n",
    "#Gini_DF.reset_index(inplace=True)\n",
    "print(Gini_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Set k number of genes to retain\"\"\"\n",
    "k = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genes = Gini_DF.index[0:k] # gene list from first instance  \n",
    "for x in [5, 54, 543, 5432, 54321] :\n",
    "    clf_RF = RandomForestClassifier(n_estimators=1000, \n",
    "                                criterion='gini', \n",
    "                                max_depth=3, \n",
    "                                min_samples_split=30, \n",
    "                                min_samples_leaf=5, \n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                max_features= 'auto', \n",
    "                                max_leaf_nodes=None, \n",
    "                                bootstrap=True, \n",
    "                                oob_score=False, \n",
    "                                n_jobs=1, \n",
    "                                random_state=x, \n",
    "                                verbose=0, \n",
    "                                warm_start=False, \n",
    "                                class_weight='balanced')\n",
    "    clf_RF.fit(X, y)\n",
    "    Gini_DF = pd.DataFrame({'Gini' :clf_RF.feature_importances_}, index=X.columns).sort_values(by = ['Gini'], axis = 0, ascending = False)\n",
    "    genes = set(genes).intersection(Gini_DF.index[0:k])\n",
    "    print('Number of Consistent (Stable) Genes:',len(genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Subset X to include only the k best features from the Gini Importance table\"\"\"\n",
    "X_k = X.loc[:,genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "for i in range(0,len(X_k.columns),1) :\n",
    "    ax = fig.add_subplot(np.ceil(len(X_k.columns)/5),5,i+1)\n",
    "    df0 = list(X_k.ix[y.loc[y=='n0'].index,i])\n",
    "    df1 = list(X_k.ix[y.loc[y=='n1'].index,i])\n",
    "    data = [df0,df1]\n",
    "    A = ax.boxplot(data, positions = [1,2], vert = False, widths = 0.5, patch_artist=True)\n",
    "    plt.setp(A['boxes'][1], color='red')\n",
    "    plt.setp(A['boxes'][0], color='blue')\n",
    "    plt.setp(A['medians'], color = 'black')\n",
    "    plt.setp(A['whiskers'], color = 'black')\n",
    "    plt.setp(A['fliers'], color = 'black', marker = '.', markersize = 3)\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.set_xlabel(X_k.columns[i], fontsize=12)\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()\n",
    "fig.legend(labels = ['n0', 'n1'], handles= [blue,red], ncol = 2, loc = 'lower center', bbox_to_anchor = (.945, 1.05))\n",
    "fig.text(-.005, 0.5, 'Metastasis state', ha='center', va='center', fontsize=24,rotation='vertical')\n",
    "fig.text(.5, -.025, 'Transcripts Per Million (TPM)', ha='center', va='center', fontsize=24)\n",
    "fig.savefig('Figures/boxplots.png', dpi = 300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Transform reduced feature dataframe to standard scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xs = pd.DataFrame(scaler.fit_transform(X_k), columns = X_k.columns, index = X_k.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA transformation\n",
    "#### Train on the scaled feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = components, whiten=False)\n",
    "pca.fit(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform with the trained PCA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xpc = pd.DataFrame(pca.transform(Xs), columns = range(0,components,1), index = X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'support files/renders_PCA.py'\n",
    "pca_results(Xs, pca)\n",
    "plt.savefig('Figures/pcaEV.png', dpi =500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sm = pd.scatter_matrix(Xpc, \n",
    "                       alpha=0.5, \n",
    "                       figsize= (10,10), \n",
    "                       diagonal = 'kde', \n",
    "                       c = y.replace({'n1': 'red','n0':'blue'}), \n",
    "                       s = 50)\n",
    "plt.savefig(\"Figures/pcaScatter.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appropriate the PCA transformed dataset via the current train, test split index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = Xpc.loc[X_train.index, :], Xpc.loc[X_test.index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Logistic Regression Algorithm\n",
    "Training with the first three principle components with cross validation to determine the optimal C parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_LR = LogisticRegression(penalty='l2',\n",
    "                              dual=False,\n",
    "                              tol=0.0001,\n",
    "                              C=1,\n",
    "                              fit_intercept=True,\n",
    "                              intercept_scaling=1,\n",
    "                              class_weight='balanced',\n",
    "                              random_state=123,\n",
    "                              solver='liblinear',\n",
    "                              max_iter=100,\n",
    "                              multi_class='ovr',\n",
    "                              verbose=0,\n",
    "                              warm_start=False,\n",
    "                              n_jobs=1)\n",
    "clf_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Performance on Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'Support Files/capstone_graphs.py'\n",
    "fig.savefig('Figures/PC3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Performance on the held-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_name = '3_PCs'\n",
    "%run -i 'Support Files/capstone_performance.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_LR = LogisticRegressionCV(Cs=10, \n",
    "                              fit_intercept=True, \n",
    "                              cv=folds, \n",
    "                              dual=False, \n",
    "                              penalty='l2', \n",
    "                              scoring='log_loss', \n",
    "                              solver='liblinear', \n",
    "                              tol=0.0001, \n",
    "                              max_iter=100, \n",
    "                              class_weight='balanced', \n",
    "                              n_jobs=1, \n",
    "                              verbose=0, \n",
    "                              refit=True, \n",
    "                              intercept_scaling=1.0, \n",
    "                              multi_class='ovr', \n",
    "                              random_state=seed)\n",
    "clf_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The optimal C term: \",clf_LR.C_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Performance on Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'Support Files/capstone_graphs.py'\n",
    "fig.savefig('Figures/optPC3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Performance on the held-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_name = '3_PCs_optimized'\n",
    "%run -i 'Support Files/capstone_performance.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate Gleason score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'gleason'] = clinicalDF.loc[X_train.index,'gleason']\n",
    "X_test.loc[:,'gleason'] = clinicalDF.loc[X_test.index, 'gleason']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Retrain Logistic Regression model with CV for C term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_LR = LogisticRegressionCV(Cs=10, \n",
    "                              fit_intercept=True, \n",
    "                              cv=folds, \n",
    "                              dual=False, \n",
    "                              penalty='l2', \n",
    "                              scoring='log_loss', \n",
    "                              solver='liblinear', \n",
    "                              tol=0.0001, \n",
    "                              max_iter=100, \n",
    "                              class_weight='balanced', \n",
    "                              n_jobs=1, \n",
    "                              verbose=0, \n",
    "                              refit=True, \n",
    "                              intercept_scaling=1.0, \n",
    "                              multi_class='ovr', \n",
    "                              random_state=seed)\n",
    "clf_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Model Performance\n",
    "Trained on First 3 PCs + gleason score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'Support Files/capstone_graphs.py'\n",
    "plt.savefig('Figures/PC3Gleason.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm = pd.scatter_matrix(X_train, \n",
    "                       alpha=0.5, \n",
    "                       figsize= (12,12), \n",
    "                       diagonal = 'kde', \n",
    "                       c = y_train.replace({'n1': 'red','n0':'blue'}), \n",
    "                       s = 50)\n",
    "plt.savefig('Figures/FeatureSM.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Performance Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_name = 'Final_Model'\n",
    "%run -i 'Support Files/capstone_performance.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is each feature important for model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Component': X_train.columns, 'coef': clf_LR.coef_[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'Support Files/final_graph.py'\n",
    "fig.savefig('Figures/FF.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Prostate Cancer Metastasis Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def risk_function(barcode, DF, clinDF, genes, scaler, fit_pca, fit_clf) :\n",
    "    self = DF.loc[barcode,genes].reshape(1,-1)\n",
    "    self = pd.DataFrame(scaler.transform(self))\n",
    "    self = pd.DataFrame(fit_pca.transform(self), index = [barcode])\n",
    "    self['gleason'] = clinDF.loc[barcode,'gleasonscore']\n",
    "    return(fit_clf.predict_proba(self)[0,1])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "risk = []\n",
    "for x in not_labeled.index :\n",
    "    risk.append(risk_function(barcode = x,\n",
    "              DF = X_all,\n",
    "              clinDF = clinical,\n",
    "              genes = genes,\n",
    "              fit_pca = pca,\n",
    "              scaler = scaler,\n",
    "              fit_clf = clf_LR))\n",
    "model_risk = pd.Series(risk, index=not_labeled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clinicalDF_all.drop(['y'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bench_risk = pd.Series(clf_LR_clin.predict_proba(clinicalDF_all.loc[not_labeled.index,:])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n0_question = X_all.loc[y[y!='n1'].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "risk = []\n",
    "for x in n0_question.index :\n",
    "    risk.append(risk_function(barcode = x,\n",
    "              DF = n0_question,\n",
    "              clinDF = clinical,\n",
    "              genes = genes,\n",
    "              fit_pca = pca,\n",
    "              scaler = scaler,\n",
    "              fit_clf = clf_LR))\n",
    "n0_risk = pd.Series(risk, index=n0_question.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize unlabeled and 'non-metastatic' cases from the TCGA cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'Support Files/free-form.py'\n",
    "fig.savefig('Figures/missing.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'Support Files/free-form2.py'\n",
    "fig.savefig('Figures/N0Analysis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to remember that the dataset utilized in this project is longitudinal and active, and indeed some cases listed as 'n0' will eventually be diagnosed as 'n1'.  Even though the model was trained on such false-negative labeled cases, some of the 'n0' class are still predicted as highly likely to metastasize.  If the dataset were linked somehow to patient records (for ethical purposes, no such link exists), then these patients should be monitored with extreme care for signs of metastasis based on the predictions made by the project model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n0_risk[n0_risk > 0.75].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "benign = feather.read_dataframe('feather_files/benign.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benign.set_index(['benign_index'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benign_tpm = transformation(benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "risk = []\n",
    "for x in benign.index :\n",
    "    risk.append(risk_function(barcode = x,\n",
    "              DF = benign,\n",
    "              clinDF = clinical,\n",
    "              genes = genes,\n",
    "              fit_pca = pca,\n",
    "              scaler = scaler,\n",
    "              fit_clf = clf_LR))\n",
    "benign_risk = pd.Series(risk, index=benign.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "A = fig.add_subplot(1,1,1)\n",
    "A.hist(benign_risk.sort_values(ascending=False),\n",
    "       bins=12,\n",
    "       facecolor='blue')\n",
    "#A.set_yscale('log')\n",
    "A.set_ylabel('Count', fontsize=16)\n",
    "A.set_xlim(0,1)\n",
    "A.set_xlabel(\"Model Probability of Metastasis\", fontsize=16)\n",
    "fig.suptitle(\"Distribution of metastasis probability for benign samples\", fontsize = 14)\n",
    "plt.show()\n",
    "fig.savefig(\"Figures/Sensitivity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
